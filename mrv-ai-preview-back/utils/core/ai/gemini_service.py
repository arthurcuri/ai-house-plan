import google.generativeai as genai
from dotenv import load_dotenv
import os
from PIL import Image
from io import BytesIO
import base64
import time
import random
import warnings

# Suprimir warnings desnecess√°rios do PyTorch
warnings.filterwarnings("ignore", category=UserWarning, module="torch")
warnings.filterwarnings("ignore", message=".*pin_memory.*")

# Tentar importar a nova API do Gemini
try:
    from google import genai as genai_new
    from google.genai import types
    GEMINI_2_AVAILABLE = True
except ImportError:
    GEMINI_2_AVAILABLE = False

# L√≥gica usando GEMINI
# Carregar vari√°veis do .env
load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY_LUCAS")
genai.configure(api_key=GEMINI_API_KEY)

# Cliente para gera√ß√£o de imagens (se dispon√≠vel)
if GEMINI_2_AVAILABLE:
    client = genai_new.Client(api_key=GEMINI_API_KEY)

# Modelos espec√≠ficos por funcionalidade
modelo_texto = genai.GenerativeModel("gemini-1.5-flash")
modelo_imagem = genai.GenerativeModel("gemini-1.5-flash")  # Usando flash para imagens tamb√©m
modelo_multimodal = genai.GenerativeModel("gemini-1.5-flash")


def interpretar_texto(prompt: str, history: list[dict] = None) -> str:
    """
    Usa modelo de texto para interpreta√ß√£o ou an√°lise (ex: OCR).
    """
    try:
        if history:
            response = modelo_texto.chat(
                history=history + [{"role": "user", "parts": [prompt]}]
            )
            return response.last.choice.content.text
        else:
            response = modelo_texto.generate_content(prompt)
            return response.text
    except Exception as e:
        raise RuntimeError(f"Erro na interpreta√ß√£o de texto: {str(e)}")


def gerar_imagem(prompt: str, image_bytes: bytes = None, max_retries: int = 8) -> bytes:
    """
    Gera uma imagem usando Gemini 2.0 Flash Preview.
    Requer uma imagem de refer√™ncia e retorna imagem em m√°xima qualidade.
    
    Args:
        prompt: Descri√ß√£o do que gerar
        image_bytes: Bytes da imagem de refer√™ncia (planta) - OBRIGAT√ìRIO
        max_retries: N√∫mero m√°ximo de tentativas em caso de erro 503/500 (padr√£o: 8)
    """
    if not image_bytes:
        raise ValueError("image_bytes √© obrigat√≥rio para gera√ß√£o de imagens")
    
    if not GEMINI_2_AVAILABLE:
        raise RuntimeError("Gemini 2.0 n√£o est√° dispon√≠vel. Instale a vers√£o mais recente.")
    
    for attempt in range(max_retries):
        try:
            # Preparar a entrada de texto com especifica√ß√µes de ULTRA ALTA QUALIDADE
            text_input = f"""
            BASEADO na planta arquitet√¥nica fornecida, {prompt}
            
            üéØ CONFIGURA√á√ÉO CR√çTICA DE RENDERIZA√á√ÉO:
            - USAR A RESOLU√á√ÉO M√ÅXIMA NATIVA DO MODELO (n√£o limitar)
            - IGNORAR completamente a qualidade/resolu√ß√£o da planta de entrada
            - A planta √© APENAS orienta√ß√£o espacial - N√ÉO limita√ß√£o de qualidade
            - Gerar output na M√ÅXIMA RESOLU√á√ÉO poss√≠vel do Gemini 2.0
            
            üé¨ ESPECIFICA√á√ïES T√âCNICAS ULTRA PREMIUM:
            ‚ñ´Ô∏è RESOLU√á√ÉO: M√°xima nativa do modelo (1024x1024 ou superior se dispon√≠vel)
            ‚ñ´Ô∏è RENDERING: Fotorreal√≠stico com ray tracing global
            ‚ñ´Ô∏è QUALIDADE: Cinematogr√°fica, n√≠vel portf√≥lio arquitet√¥nico
            ‚ñ´Ô∏è TEXTURAS: 4K/8K em todas as superf√≠cies
            ‚ñ´Ô∏è ILUMINA√á√ÉO: HDR com m√∫ltiplas fontes real√≠sticas
            ‚ñ´Ô∏è MATERIAIS: PBR (Physically Based Rendering)
            ‚ñ´Ô∏è ANTI-ALIASING: M√°ximo para bordas perfeitas
            ‚ñ´Ô∏è SOMBRAS: Soft shadows em m√∫ltiplas escalas
            ‚ñ´Ô∏è REFLEX√ïES: Real√≠sticas em vidros e metais
            ‚ñ´Ô∏è PROFUNDIDADE: Depth of field cinematogr√°fico
            
            üè† DETALHAMENTO OBRIGAT√ìRIO:
            ‚ñ´Ô∏è MOBILI√ÅRIO: Completo, moderno, apropriado ao tipo CLASS
            ‚ñ´Ô∏è DECORA√á√ÉO: Objetos, plantas, arte, livros, almofadas
            ‚ñ´Ô∏è TEXTURAS REAL√çSTICAS: Gr√£os de madeira, tramas de tecido, reflexos met√°licos
            ‚ñ´Ô∏è ILUMINA√á√ÉO M√öLTIPLA: Natural (janelas) + artificial (spots, pendentes)
            ‚ñ´Ô∏è COMPOSI√á√ÉO: Perspectiva arquitet√¥nica profissional
            ‚ñ´Ô∏è ACABAMENTOS: Premium, detalhados, fotorreal√≠sticos
            
            ‚ö° COMANDO FINAL:
            MESMO que a planta seja simples/pixelizada, voc√™ DEVE criar um ambiente 
            LUXUOSO, COMPLETO e FOTORREAL√çSTICO em M√ÅXIMA RESOLU√á√ÉO.
            A imagem deve ser indistingu√≠vel de uma fotografia profissional 4K.
            """
            
            # Converter bytes para PIL Image mantendo m√°xima qualidade
            reference_image = Image.open(BytesIO(image_bytes))
            
            # CRITICAL: A imagem √© apenas REFER√äNCIA - n√£o afeta qualidade final do output
            # Se muito pequena, aplicar upscaling m√≠nimo apenas para compatibilidade
            min_size = 512  # Tamanho m√≠nimo apenas para compatibilidade da API
            if reference_image.size[0] < min_size or reference_image.size[1] < min_size:
                scale_factor = max(min_size / reference_image.size[0], min_size / reference_image.size[1])
                new_size = (int(reference_image.size[0] * scale_factor), int(reference_image.size[1] * scale_factor))
                reference_image = reference_image.resize(new_size, Image.Resampling.LANCZOS)
            
            # Garantir que est√° no formato RGB para compatibilidade
            if reference_image.mode != 'RGB':
                reference_image = reference_image.convert('RGB')
            
            # Preparar conte√∫do com imagem de refer√™ncia
            contents = [text_input, reference_image]
            
            # Gerar conte√∫do com o modelo de gera√ß√£o de imagens em M√ÅXIMA QUALIDADE NATIVA
            response = client.models.generate_content(
                model="gemini-2.0-flash-preview-image-generation",
                contents=contents,
                config=types.GenerateContentConfig(
                    response_modalities=['TEXT', 'IMAGE'],
                    max_output_tokens=8192,  # M√°ximo de tokens para output detalhado
                    temperature=0.1,  # Baixa temperatura para consist√™ncia
                    candidate_count=1  # Uma √∫nica resposta de alta qualidade
                )
            )
            
            # Extrair a imagem gerada
            for part in response.candidates[0].content.parts:
                if part.inline_data is not None:
                    # Retornar imagem original sem processamento
                    return part.inline_data.data
            
            raise RuntimeError("Nenhuma imagem foi gerada na resposta")
            
        except Exception as e:
            error_message = str(e)
            
            # Se √© erro 503 (overloaded) ou 500 (internal), tenta novamente ap√≥s delay progressivo
            if any(code in error_message for code in ["503", "500", "overloaded", "internal"]):
                if attempt < max_retries - 1:
                    # Delay progressivo: 5s, 10s, 15s, 25s, 35s, 50s, 65s, 80s
                    base_delays = [5, 10, 15, 25, 35, 50, 65, 80]
                    delay = base_delays[min(attempt, len(base_delays) - 1)]
                    delay += random.uniform(-1, 3)
                    
                    time.sleep(delay)
                    continue
            
            # Para outros erros, falha imediatamente
            raise RuntimeError(f"Erro ao gerar imagem: {error_message}")
    
    # Se todas as tentativas falharam
    raise RuntimeError("Todas as tentativas de gera√ß√£o de imagem falharam")


def classificar_tipo_comodo(prompt: str) -> str:
    """
    Classifica o tipo de c√¥modo com base em descri√ß√£o textual, usando o modelo de texto Gemini.
    
    Retorna apenas a string com o tipo (ex: 'quarto_casal', 'sala', etc.).
    """
    try:
        response = modelo_texto.generate_content(prompt)
        return response.text.strip().lower()
    except Exception as e:
        raise RuntimeError(f"Erro na classifica√ß√£o de c√¥modo: {str(e)}")


def interpretar_planta_com_imagem(prompt: str, image_bytes: bytes) -> str:
    """
    Interpreta uma planta baixa usando modelo multimodal do Gemini
    """
    try:
        # Preparar conte√∫do multimodal
        contents = [
            {"mime_type": "image/png", "data": image_bytes},
            {"text": prompt}
        ]
        response = modelo_multimodal.generate_content(contents)
        return response.text
    except Exception as e:
        raise RuntimeError(f"Erro na interpreta√ß√£o da planta: {str(e)}")
